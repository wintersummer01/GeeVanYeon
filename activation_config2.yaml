experiment_name: Activation_learning

# Model
model_class: AFMM
hidden_dim: 4
num_layers: 6
initializer: 0.04

# Training
loss_type: mse
initial_epoch: 0
epochs: 10000
learning_rate: 1.0e-2
lr_milestone_epoch: [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000]
clip_max_norm: 0.0
shutup: False

# Dataset
dataset_root: 'nonlinear2.csv'
num_workers: 16
batch_size: 8

# logging
log_dir: activation_logs/
save_model: True
save_every: 1000
pretrain_ckpt: null

# Environments
seed: 1030
gpu_ids: ["0", "1", "2", "3"]
